{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91862d0a",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2904eeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tharindu\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1432fa18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 6us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 82s 3us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 15s 3us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7047b4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b94197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tharindu\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LAYERS = [ tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.LeakyReLU(),  ## Activation function for the above layer . Like this we can also \n",
    "    # seperately define the activation function \n",
    "    tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.LeakyReLU(), ## Activation function for the above layer \n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")]\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential(LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9668f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ff66d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 300)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266610 (1.02 MB)\n",
      "Trainable params: 266610 (1.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "488269f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Tharindu\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tharindu\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tharindu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tharindu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 - 3s - loss: 0.6811 - accuracy: 0.7692 - val_loss: 0.5000 - val_accuracy: 0.8294 - 3s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "1719/1719 - 3s - loss: 0.4817 - accuracy: 0.8315 - val_loss: 0.4344 - val_accuracy: 0.8514 - 3s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "1719/1719 - 3s - loss: 0.4406 - accuracy: 0.8447 - val_loss: 0.5209 - val_accuracy: 0.8074 - 3s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "1719/1719 - 3s - loss: 0.4169 - accuracy: 0.8544 - val_loss: 0.4011 - val_accuracy: 0.8616 - 3s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "1719/1719 - 3s - loss: 0.4009 - accuracy: 0.8592 - val_loss: 0.3869 - val_accuracy: 0.8660 - 3s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "1719/1719 - 3s - loss: 0.3843 - accuracy: 0.8650 - val_loss: 0.3823 - val_accuracy: 0.8710 - 3s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "1719/1719 - 3s - loss: 0.3738 - accuracy: 0.8669 - val_loss: 0.3729 - val_accuracy: 0.8732 - 3s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "1719/1719 - 3s - loss: 0.3640 - accuracy: 0.8701 - val_loss: 0.3992 - val_accuracy: 0.8572 - 3s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "1719/1719 - 3s - loss: 0.3547 - accuracy: 0.8744 - val_loss: 0.3729 - val_accuracy: 0.8670 - 3s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "1719/1719 - 3s - loss: 0.3467 - accuracy: 0.8766 - val_loss: 0.3633 - val_accuracy: 0.8728 - 3s/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7854c650",
   "metadata": {},
   "source": [
    "# BN approach one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebd4bbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d57dec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERS_BN = [\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.BatchNormalization(),   ### Applying the batch normalization for the above layer \n",
    "    tf.keras.layers.Dense(300, activation=\"relu\"),  ### Activation fucntion for the above layer \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "]\n",
    "\n",
    "model = tf.keras.models.Sequential(LAYERS_BN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38968def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 784)               3136      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 300)               1200      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 100)               400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271346 (1.04 MB)\n",
      "Trainable params: 268978 (1.03 MB)\n",
      "Non-trainable params: 2368 (9.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3884f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn1 = model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfc3631a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x181ae0be590>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd4f8472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization/gamma:0 True\n",
      "batch_normalization/beta:0 True\n",
      "batch_normalization/moving_mean:0 False\n",
      "batch_normalization/moving_variance:0 False\n"
     ]
    }
   ],
   "source": [
    "for variable in bn1.variables:\n",
    "  print(variable.name, variable.trainable)   # whether those are trainable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1eaf920b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f1c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8632f6d3",
   "metadata": {},
   "source": [
    "# BN approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b15490bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02332b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERS_BN_BIAS_FALSE = [\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(300, use_bias=False),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(\"relu\"),\n",
    "    tf.keras.layers.Dense(100, use_bias=False),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "]\n",
    "\n",
    "model = tf.keras.models.Sequential(LAYERS_BN_BIAS_FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27be4902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 784)               3136      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 300)               235200    \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 300)               1200      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation (Activation)     (None, 300)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               30000     \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 100)               400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 270946 (1.03 MB)\n",
      "Trainable params: 268578 (1.02 MB)\n",
      "Non-trainable params: 2368 (9.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4dcc72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd63da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02d953f5",
   "metadata": {},
   "source": [
    "# Transfer Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be2f0ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 300)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266610 (1.02 MB)\n",
      "Trainable params: 266610 (1.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1719/1719 - 3s - loss: 1.5065 - accuracy: 0.6133 - val_loss: 0.9119 - val_accuracy: 0.8160 - 3s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "1719/1719 - 3s - loss: 0.7212 - accuracy: 0.8360 - val_loss: 0.5721 - val_accuracy: 0.8684 - 3s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "1719/1719 - 3s - loss: 0.5274 - accuracy: 0.8651 - val_loss: 0.4622 - val_accuracy: 0.8820 - 3s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "1719/1719 - 3s - loss: 0.4516 - accuracy: 0.8778 - val_loss: 0.4086 - val_accuracy: 0.8922 - 3s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "1719/1719 - 3s - loss: 0.4103 - accuracy: 0.8865 - val_loss: 0.3761 - val_accuracy: 0.8994 - 3s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "1719/1719 - 3s - loss: 0.3833 - accuracy: 0.8923 - val_loss: 0.3541 - val_accuracy: 0.9048 - 3s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "1719/1719 - 3s - loss: 0.3638 - accuracy: 0.8966 - val_loss: 0.3375 - val_accuracy: 0.9072 - 3s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "1719/1719 - 3s - loss: 0.3487 - accuracy: 0.9011 - val_loss: 0.3239 - val_accuracy: 0.9108 - 3s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "1719/1719 - 3s - loss: 0.3363 - accuracy: 0.9041 - val_loss: 0.3140 - val_accuracy: 0.9120 - 3s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "1719/1719 - 3s - loss: 0.3262 - accuracy: 0.9070 - val_loss: 0.3048 - val_accuracy: 0.9150 - 3s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tharindu\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "LAYERS = [ tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")]\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential(LAYERS)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid), verbose=2)\n",
    "\n",
    "model.save(\"pretrained_mnist_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db26b815",
   "metadata": {},
   "source": [
    "#### Transfer Learning \n",
    "\n",
    "#### New problem : Classify the hand written digits into odd and even "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec9c9b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_mnist_model = tf.keras.models.load_model(\"pretrained_mnist_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68038c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 300)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266610 (1.02 MB)\n",
      "Trainable params: 266610 (1.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained_mnist_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d02728d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten_3: True\n",
      "dense_9: True\n",
      "leaky_re_lu_2: True\n",
      "dense_10: True\n",
      "leaky_re_lu_3: True\n",
      "dense_11: True\n"
     ]
    }
   ],
   "source": [
    "for layer in pretrained_mnist_model.layers:\n",
    "  print(f\"{layer.name}: {layer.trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6ca1873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten_3: False\n",
      "dense_9: False\n",
      "leaky_re_lu_2: False\n",
      "dense_10: False\n",
      "leaky_re_lu_3: False\n"
     ]
    }
   ],
   "source": [
    "for layer in pretrained_mnist_model.layers[:-1]: #leaves the last layer unfreezed =>last layer is trainable\n",
    "  layer.trainable = False # freezing the layers from getting trained\n",
    "  print(f\"{layer.name}: {layer.trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ae4ed45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten_3: False\n",
      "dense_9: False\n",
      "leaky_re_lu_2: False\n",
      "dense_10: False\n",
      "leaky_re_lu_3: False\n",
      "dense_11: True\n"
     ]
    }
   ],
   "source": [
    "for layer in pretrained_mnist_model.layers:\n",
    "  print(f\"{layer.name}: {layer.trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9252d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  del new_model\n",
    "except:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb2f1c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_pretrained_layers = pretrained_mnist_model.layers[:-1]\n",
    "new_model = tf.keras.models.Sequential(lower_pretrained_layers)\n",
    "\n",
    "new_model.add(\n",
    "    tf.keras.layers.Dense(2, activation=\"softmax\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "275dacc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 300)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 265802 (1.01 MB)\n",
      "Trainable params: 202 (808.00 Byte)\n",
      "Non-trainable params: 265600 (1.01 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1569da05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "09375f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y_train%2 == 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e6314cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 8)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0], y_train[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ac99ac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_even_odd_labels(labels):\n",
    "  for idx, label in enumerate(labels):\n",
    "    labels[idx] = np.where(label % 2 == 0, 1, 0)\n",
    "  return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e0c22e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bin, y_test_bin, y_valid_bin = update_even_odd_labels([y_train, y_test, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a901f650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c335a9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    }
   ],
   "source": [
    "new_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5eb2105c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 - 2s - loss: 0.3189 - accuracy: 0.8644 - val_loss: 0.2740 - val_accuracy: 0.8912 - 2s/epoch - 1ms/step\n",
      "Epoch 2/10\n",
      "1719/1719 - 2s - loss: 0.2863 - accuracy: 0.8815 - val_loss: 0.2580 - val_accuracy: 0.8972 - 2s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "1719/1719 - 2s - loss: 0.2771 - accuracy: 0.8868 - val_loss: 0.2512 - val_accuracy: 0.9004 - 2s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "1719/1719 - 2s - loss: 0.2711 - accuracy: 0.8899 - val_loss: 0.2472 - val_accuracy: 0.9042 - 2s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "1719/1719 - 2s - loss: 0.2665 - accuracy: 0.8921 - val_loss: 0.2414 - val_accuracy: 0.9062 - 2s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "1719/1719 - 2s - loss: 0.2633 - accuracy: 0.8941 - val_loss: 0.2386 - val_accuracy: 0.9068 - 2s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "1719/1719 - 2s - loss: 0.2600 - accuracy: 0.8957 - val_loss: 0.2360 - val_accuracy: 0.9066 - 2s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "1719/1719 - 2s - loss: 0.2579 - accuracy: 0.8965 - val_loss: 0.2394 - val_accuracy: 0.9060 - 2s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "1719/1719 - 2s - loss: 0.2557 - accuracy: 0.8980 - val_loss: 0.2342 - val_accuracy: 0.9096 - 2s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "1719/1719 - 2s - loss: 0.2541 - accuracy: 0.8981 - val_loss: 0.2346 - val_accuracy: 0.9110 - 2s/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "history = new_model.fit(X_train, y_train_bin, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid_bin), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b459d136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2539 - accuracy: 0.9015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25388863682746887, 0.9014999866485596]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.evaluate(X_test, y_test_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f57774ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7, 2, 1], dtype=uint8), array([0, 1, 0]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "\n",
    "y_test[:3], y_test_bin[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3306840f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(new_model.predict(X_new), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110a3845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcba46c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e756c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2da317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
